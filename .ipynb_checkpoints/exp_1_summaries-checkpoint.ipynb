{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f685dccf-a08c-40c5-aa83-4a16ebe6e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import GEN_SUMMARY\n",
    "from langchain_groq import ChatGroq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b780b9-2aa2-4cd2-9094-6dc5cd2a42ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 1 = 2.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    model= \"llama-3.1-70b-versatile\",\n",
    "    groq_api_key = \"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\",\n",
    "    temperature =0 \n",
    ")\n",
    "\n",
    "# check if it is working \n",
    "response = llm.invoke(\"what is 1+1?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b1578b-917d-4894-8ee3-bf7ab92e3305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your task is to summarize the comments as CONCISELY as possible. No need for formal language or nice phrasing. Determine the number of UNIQUE viewpoints you can find. Beware, not each comment would have a unique viewpoint. DO NOT use your knowledge about the world, stick to what the participants said. Do not put quotes around your response. Give the ouput in a JSON format, with a number(from 1) for EACH UNIQUE viewpoint'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GEN_SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44670251-afe0-4189-b7d0-b511a989ce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm ready to summarize the comments. However, I don't see any comments provided. Please provide the comments you'd like me to summarize, and I'll do my best to condense them into a JSON format with unique viewpoints numbered from 1.\n",
      "\n",
      "Please go ahead and provide the comments.\n"
     ]
    }
   ],
   "source": [
    "def generate_slate(prompt):\n",
    "\n",
    "\n",
    "    prompt = f\"Batch {batch_number} of {total_batches}: Your task is to summarize the comments as CONCISELY as possible. \"\\\n",
    "             \"No need for formal language or nice phrasing. Determine the number of UNIQUE viewpoints you can find. \" \\\n",
    "             \"Beware, not each comment would have a unique viewpoint. DO NOT use your knowledge about the world, \" \\\n",
    "             \"stick to what the participants said. Do not put quotes around your response. Give the output in a JSON format, \" \\\n",
    "             \"with a number (from 1) for EACH UNIQUE viewpoint.\\n\\n\"\n",
    "    \n",
    "    # Clarify that this is part of a sequence of batches\n",
    "    prompt += \"Please remember that you're processing a sequence of batches. \" \\\n",
    "              \"You should accumulate the viewpoints across batches and give a unique number (from 1) for each viewpoint \" \\\n",
    "              \"across all the comments you've seen so far.\\n\\n\"\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.content)\n",
    "\n",
    "generate_slate(GEN_SUMMARY)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17352913-9fdb-47b9-9e77-6edabb4541b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm ready to summarize the comments. However, I don't see any comments provided. Please provide the comments you'd like me to summarize, and I'll do my best to condense them into a JSON format with unique viewpoints numbered from 1.\n",
      "\n",
      "Please go ahead and provide the comments.\n"
     ]
    }
   ],
   "source": [
    "MAX_TOKENS = 32,768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb034adb-146c-44f6-941e-c8062c6a3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm.max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdaddb1-e382-4019-89d1-8f102e983552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
